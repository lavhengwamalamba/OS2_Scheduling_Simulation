autoplot(train) + autolayer(modelh)
(ggAcf(train))
accuracy(modelh , test)
autoplot(train) + autolayer(modelh)
df <- fpp3::us_change
library("fpp3")
library("ggplot2")
library("forecast")
df <- fpp3::us_change
df
View(df)
library("fpp3")
library("ggplot2")
library("forecast")
df <- fpp3::us_change$Consumption
df
dt <- ts(df)
autoplot(dt)
summary(dt)
ndiffs(dt)
train <- window(us_change , start = 0 , end = c(170))
df
library("fpp3")
library("ggplot2")
library("forecast")
df <- fpp3::us_change$Consumption
df
dt <- ts(df)
autoplot(dt)
summary(dt)
ndiffs(dt)
(df <- fpp3::us_change$Consumption)
View(df)
View(df)
df
library("fpp3")
library("ggplot2")
library("forecast")
(df <- fpp3::us_change$Consumption)
View(df)
dt <- ts(df)
autoplot(dt)
summary(dt)
ndiffs(dt)
train <- window(us_change , start = 0 , end = c(170))
library("fpp3")
library("ggplot2")
library("forecast")
(df <- fpp3::us_change$Consumption)
View(df)
dt <- ts(df)
autoplot(dt)
summary(dt)
summary(dt)
ndiffs(dt)
train <- window(dt , start = 0 , end = c(170))
test <- window(dt , start = 171 )
autoplot(train) + autolayer(test)
ggAcf(train)
train <- window(dt , end = 170)
test <- window(dt , start = 171 )
autoplot(train) + autolayer(test)
ggAcf(train)
ggPacf(train)
Arima(train, order = c(3,0,3))
auto.arima(train)
checkresiduals(train)
checkresiduals(auto.arima(train))
library("fpp3")
library("ggplot2")
library("forecast")
(df <- fpp3::us_change$Consumption)
View(df)
dt <- ts(df)
autoplot(dt)
summary(dt)
ndiffs(dt)
train <- window(dt , end = 170)
test <- window(dt , start = 171 )
autoplot(train) + autolayer(test)
ggAcf(train)
ggPacf(train)
Arima(train, order = c(3,0,3))
auto.arima(train)
checkresiduals(auto.arima(train))
b1 = sample(os,size = 7, replace = TRUE)
# Creating a sample
os = c(5, 8,13,15,10,22,30)
b1 = sample(os,size = 7, replace = TRUE)
#############################Lecture 3############################
#Here we are going to be working with a sample which looks at the time it takes for debtors to pay back their debt
pdelays = c(34,34,34,35,36,36,37,37,37,38,38,38,38,38,38,39,39,39,40,41,41,41,41,42,42,43,44,46)
boxplot(pdelays, main= "Box and whisker")
length(pdelays)
#############################Lecture 3############################
#Here we are going to be working with a sample which looks at the time it takes for debtors to pay back their debt
pdelays = c(37,42,38,44,39,35,43,41,42,38,36,34,37,42,36,38,41,39,39,37,34,34,41,41,40,38,38,46,38,42)
length(pdelays)
# Now we start working with bootstraps, we are going to use a for loop using some randomisation algorithm to help us get those bootstraps
#First, we want to start by creating a matrix with everything inside being Zero first. Dimention 1 ir rows and dimention 2 is Columns
btsr = matrix(NA , ncol = 30, nrow = 5000)
btsr
#Now we change that bootstrap matrix into actual values or observations
for (i in 1:5000)
{s = sample(pdelays, size = 30, replacement = TRUE)
btsr[i,] = s}
#So now, firstly, we want to find our mean for each bootstrap and store it in its own space... basically, another matrix but with one colomn of means
bstrm = apply(bstr, 1, mean)
pdelays = c(37,42,38,44,39,35,43,41,42,38,36,34,37,42,36,38,41,39,39,37,34,34,41,41,40,38,38,46,38,42)
boxplot(pdelays, main= "Box and whisker")
# Now we start working with bootstraps, we are going to use a for loop using some randomisation algorithm to help us get those bootstraps
#First, we want to start by creating a matrix with everything inside being Zero first. Dimention 1 ir rows and dimention 2 is Columns
btsr = matrix(NA , ncol = 30, nrow = 5000)
#We fill it with NAs and it has 30 columns because we have 30 observations to look at and 5000 rows because thats how many bootstarps we want
#Now we change that bootstrap matrix into actual values or observations
for (i in 1:5000)
{s = sample(pdelays, size = 30, replacement = TRUE)
btsr[i,] = s}
os = c(0.35,1.15,0.40,0.08,0.03,0.20,0.10,0.15)
osmean = mean(od)
osmean = mean(os)
osmean
ossd = sd(os)
ossd
##############################Question 1############################################
os = c(0.35,1.15,0.40,0.08,0.03,0.20,0.10,0.15)
osmean = mean(os)
osmean
ossd = sd(os)
ossd
#Bootstraps
btsr <- matrix(NA, 1000 , 8)
for (i in 1:1000)
{
s = sampple(os , size = 8, replace = TRUE)
btsr[i,] = s
}
##############################Question 1############################################
os = c(0.35,1.15,0.40,0.08,0.03,0.20,0.10,0.15)
osmean = mean(os)
osmean
ossd = sd(os)
ossd
#Bootstraps
btsr <- matrix(NA, 1000 , 8)
for (i in 1:1000)
{
s = sample(os , size = 8, replace = TRUE)
btsr[i,] = s
}
btsrm = apply (btsr, 1, mean)
sortmean = sort(btsr)
sortmean[1]
sortmean[10]
sortmean[25]
sortmean[50]
sortmean[100]
sortmean[900]
sortmean[950]
sortmean[975]
sortmean[990]
sortmean[1000]
btsrmean = mean(btsrm)
# 95% Confidence interval
cat("95% CI :(", sortmnean[0.025*5000],"," , sortmean[0.975*1000], ")")
# 95% Confidence interval
cat("95% CI :(", sortmean[0.025*5000],"," , sortmean[0.975*1000], ")")
###################################Question 2################################
os2 = c(30,37,43,42,43,45,36,33,41,38)
os2mean = mean(os2)
btsr2 = matrix(NA,1000 , 10)
#Creating Bootstraps using the increasing seeds
for (i in 1:1000) {
set.seed(i)
s1 = sample(os2, size = 10, replace = TRUE)
btsr2 = s1
}
btsr2m = apply(btsr2 , 1, mean)
btsr2sd = apply(btsr2,1, sd)
##############################Question 1############################################
os = c(0.35,1.15,0.40,0.08,0.03,0.20,0.10,0.15)
osmean = mean(os)
osmean
ossd = sd(os)
ossd
#Bootstraps
btsr <- matrix(NA, 1000 , 8)
for (i in 1:1000)
{
s = sample(os , size = 8, replace = TRUE)
btsr[i,] = s
}
btsrm = apply (btsr, 1, mean)
sortmean = sort(btsr)
sortmean[1]
sortmean[10]
sortmean[25]
sortmean[50]
sortmean[100]
sortmean[900]
sortmean[950]
sortmean[975]
sortmean[990]
sortmean[1000]
btsrmean = mean(btsrm)
# 95% Confidence interval
cat("95% CI :(", sortmean[0.025*5000],"," , sortmean[0.975*1000], ")")
###################################Question 2################################
os2 = c(30,37,43,42,43,45,36,33,41,38)
os2mean = mean(os2)
btsr2 = matrix(NA,1000 , 10)
#Creating Bootstraps using the increasing seeds
for (i in 1:1000) {
set.seed(i)
s1 = sample(os2, size = 10, replace = TRUE)
btsr2 = s1
}
btsr2m = apply(btsr2 , 1, mean)
os = c(0.35,1.15,0.40,0.08,0.03,0.20,0.10,0.15)
osmean = mean(os)
osmean
ossd = sd(os)
ossd
##############################Question 1#######################################
os = c(0.35,1.15,0.40,0.08,0.03,0.20,0.10,0.15)
osmean = mean(os)
osmean
ossd = sd(os)
ossd
#Bootstraps
btsr <- matrix(NA, 1000 , 8)
for (i in 1:1000)
{
s = sample(os , size = 8, replace = TRUE)
btsr[i,] = s
}
btsrm = apply (btsr, 1, mean)
sortmean = sort(btsrm)
sortmean[1]
sortmean[10]
sortmean[25]
sortmean[50]
sortmean[100]
sortmean[900]
sortmean[950]
sortmean[975]
sortmean[990]
sortmean[1000]
btsrmean = mean(btsrm)
# 95% Confidence interval
cat("95% CI :(", sortmean[0.025*5000],"," , sortmean[0.975*1000], ")")
###################################Question 2#################################
os2 = c(30,37,43,42,43,45,36,33,41,38)
os2mean = mean(os2)
os2mean
btsr2 = matrix(NA,1000 , 10)
#Creating Bootstraps using the increasing seeds
for (i in 1:1000) {
set.seed(i)
s1 = sample(os2, size = 10, replace = TRUE)
btsr2[i,] = s1
}
btsr2m = apply(btsr2 , 1, mean)
btsr2sd = apply(btsr2,1, sd)
#Wanna store the t.tests in a mati
btsr2ttest = matrix(0, 1000,1)
for(i in 1:1000){
btsr2ttest[i] = (btsr2m[i]-37)/(btsr2sd[i]/sqrt(10))
}
ttestaverage = mean(btsr2ttest)
ttestaverage
randsample = c(0.05,2.11,2.08,5.40,5.52,6.78,8.06,8.54,9.57,21.89)
mrandsample = median(randsample)
mrandsample
data
#data <- read.table("C:\\Users\\lavhe\\OneDrive - University of Cape Town\\2024\\STA3030F\\Quizzes\\Quiz 5\\aov6.txt")
data <- read.table("C:\\Users\\lavhe\\OneDrive - University of Cape Town\\2024\\STA3030F\\Quizzes\\Quiz 5\\aov6.txt", header = TRUE, sep = "\t", dec = ",")
data
m1 = mean(data$HS_A)
m2 = mean(data$HS_B)
m3 = mean(data$HS_C)
m4 = mean(data$HS_D)
om = mean(data)
data <- read.table("C:\\Users\\lavhe\\OneDrive - University of Cape Town\\2024\\STA3030F\\Quizzes\\Quiz 5\\aov6.txt", header = TRUE, sep = "\t", dec = ",")
data
LOC-list ("numeric", length=4)
data <- read.table("C:\\Users\\lavhe\\OneDrive - University of Cape Town\\2024\\STA3030F\\Quizzes\\Quiz 5\\aov6.txt", header = TRUE, sep = "\t", dec = ",")
data
LOC=list ("numeric", length=4)
LOC[[1]] = data$HS_A
LOC[[2]] = data$HS_B
LOC[[3]] = data$HS_C
LOC[[4]] = data$HS_D
N-length(unlist (LOC)) #total observations
N=length(unlist (LOC)) #total observations
n=c(length (LOC[[1]]), length (LOC[[2]]), length (LOC[[3]]), length (LOC[[4]])) #vector of k-length (LOC) # number of groups, k
K = length(LOC)
B=5000 #number of bootstraps
RATIOS=Yi.=vector("numeric")
Y..=mean (unlist (LOC))
SSE=SST=0
for (j in 1:k)
{Yi. [j]-mean (LOC[[j]])
SSE-SSE+Sum((LOC[[j]]-Yi. [j])^2)
SST-SST+n[j]*(Y. [j]-Y..)^2}
data <- read.table("C:\\Users\\lavhe\\OneDrive - University of Cape Town\\2024\\STA3030F\\Quizzes\\Quiz 5\\aov6.txt", header = TRUE, sep = "\t", dec = ",")
data
LOC=list ("numeric", length=4)
LOC[[1]] = data$HS_A
LOC[[2]] = data$HS_B
LOC[[3]] = data$HS_C
LOC[[4]] = data$HS_D
N=length(unlist (LOC)) #total observations
n=c(length (LOC[[1]]), length (LOC[[2]]), length (LOC[[3]]), length (LOC[[4]])) #vector of k-length (LOC) # number of groups, k
k = length(LOC)
B=5000 #number of bootstraps
RATIOS=Yi.=vector("numeric")
Y..=mean (unlist (LOC))
SSE=SST=0
for (j in 1:k)
{Yi. [j]-mean (LOC[[j]])
SSE-SSE+Sum((LOC[[j]]-Yi. [j])^2)
SST-SST+n[j]*(Y. [j]-Y..)^2}
data <- read.table("C:\\Users\\lavhe\\OneDrive - University of Cape Town\\2024\\STA3030F\\Quizzes\\Quiz 5\\aov6.txt", header = TRUE, sep = "\t", dec = ",")
data
LOC=list ("numeric", length=4)
LOC[[1]] = data$HS_A
LOC[[2]] = data$HS_B
LOC[[3]] = data$HS_C
LOC[[4]] = data$HS_D
N=length(unlist (LOC)) #total observations
n=c(length (LOC[[1]]), length (LOC[[2]]), length (LOC[[3]]), length (LOC[[4]])) #vector of k-length (LOC) # number of groups, k
k = length(LOC)
B=5000 #number of bootstraps
RATIOS=Yi.=vector("numeric")
Y..=mean (unlist (LOC))
SSE=SST=0
for (j in 1:k)
{Yi. [j]-mean (LOC[[j]])
SSE=SSE+Sum((LOC[[j]]-Yi. [j])^2)
SST=SST+n[j]*(Y. [j]-Y..)^2}
metric_times_1_with_500_patrons <- read.csv("C:/Users/lavhe/OneDrive - University of Cape Town/2024/CSC3002F/Assignments/Assignment_4_OS_2/OS2_Scheduling_Simulation/metric_times_1_with_500_patrons.csv")
View(metric_times_1_with_500_patrons)
ist(metric_times_1_with_500_patrons$`Waiting.Time`, main = "WhateverName you want", col = "thistle", xlab = "just type", ylab = "Another just type", xlim = c(0,250000))
hist(metric_times_1_with_500_patrons$`Waiting.Time`, main = "WhateverName you want", col = "thistle", xlab = "just type", ylab = "Another just type", xlim = c(0,250000))
hist(throughputs_1_with_500_patrons$`Count`, main = "Another Whatever", col = "goldenrod2", xlab = "blaaa", ylab = "olll")
throughputs_1_with_500_patrons <- read.csv("C:/Users/lavhe/OneDrive - University of Cape Town/2024/CSC3002F/Assignments/Assignment_4_OS_2/OS2_Scheduling_Simulation/throughputs_1_with_500_patrons.csv")
View(throughputs_1_with_500_patrons)
hist(metric_times_1_with_500_patrons$`Waiting.Time`, main = "WhateverName you want", col = "thistle", xlab = "just type", ylab = "Another just type", xlim = c(0,250000))
hist(throughputs_1_with_500_patrons$`Count`, main = "Another Whatever", col = "goldenrod2", xlab = "blaaa", ylab = "olll")
#hist(throughputs_1_with_500_patrons$Count, breaks = seq(0, max(throughputs_1_with_500_patrons$Count), by = 10000), xlab = "Time Interval", ylab = "Count", main = "Histogram of Throughputs with 500 Patrons")
library(ggplot2)
#ggplot(throughputs_1_with_500_patrons, aes(x = throughputs_1_with_500_patrons$Time.Interval.milliseconds, y = throughputs_1_with_500_patrons$Count)) +
# geom_bar(stat = "identity") +
#labs(x = "Time Interval (milliseconds)", y = "Count") +
#ggtitle("Histogram of Throughputs")
# Calculate the mean of the Count column
mean_count <- mean(throughputs_1_with_500_patrons$Count)
# Create the plot
ggplot(throughputs_1_with_500_patrons, aes(x = throughputs_1_with_500_patrons$Time.Interval.milliseconds, y = throughputs_1_with_500_patrons$Count)) +
geom_bar(stat = "identity") +
geom_hline(yintercept = mean_count, color = "red", linetype = "dashed") +
labs(x = "Time Interval (milliseconds)", y = "Count", title = "Histogram of Throughputs with Overall Average Count") +
annotate("text", x = Inf, y = mean_count, label = paste("Overall Average Count =", round(mean_count, 2)), hjust = -0.1, vjust = -1, color = "red")
# Calculate the mean of the Count column
mean_count <- mean(throughputs_1_with_500_patrons$Count)
# Create the histogram /////// this will actually give really good insight for me as well
hist(throughputs_1_with_500_patrons$Count,
main = "Histogram of Throughputs with Average Count",
xlab = "Count",
ylab = "Frequency",
col = "lightblue")
# Add a line for the mean
abline(v = mean_count, col = "red", lty = 2)
setwd("C:/Users/lavhe/OneDrive - University of Cape Town/2024/CSC3002F/Assignments/Assignment_4_OS_2/OS2_Scheduling_Simulation")
clear
# Load the required libraries
library(ggplot2)
library(dplyr)
library(readr)
# Function to plot the distributions and averages
plot_metric <- function(metric_name, file_pattern) {
# Read the data files
fcfs_files <- list.files(pattern = paste0("^metric_times_0_with_", file_pattern, ".csv$"))
sjf_files <- list.files(pattern = paste0("^metric_times_1_with_", file_pattern, ".csv$"))
fcfs_data <- lapply(fcfs_files, read_csv) %>% bind_rows()
sjf_data <- lapply(sjf_files, read_csv) %>% bind_rows()
# Calculate averages
fcfs_avg <- mean(fcfs_data[[metric_name]], na.rm = TRUE)
sjf_avg <- mean(sjf_data[[metric_name]], na.rm = TRUE)
# Plot the distributions
ggplot() +
geom_histogram(data = fcfs_data, aes(x = .data[[metric_name]], fill = "FCFS"), alpha = 0.5, bins = 30) +
geom_histogram(data = sjf_data, aes(x = .data[[metric_name]], fill = "SJF"), alpha = 0.5, bins = 30) +
facet_wrap(~Patron.ID, ncol = 3) +
labs(
title = paste(metric_name, "Distributions"),
x = metric_name,
y = "Frequency",
fill = "Algorithm"
) +
geom_vline(xintercept = fcfs_avg, color = "red", linetype = "dashed", size = 1) +
geom_vline(xintercept = sjf_avg, color = "blue", linetype = "dashed", size = 1) +
annotate("text", x = Inf, y = Inf, label = paste("FCFS Average:", round(fcfs_avg, 2)), hjust = 1.1, vjust = 1.5, color = "red") +
annotate("text", x = Inf, y = Inf, label = paste("SJF Average:", round(sjf_avg, 2)), hjust = 1.1, vjust = 2, color = "blue") +
theme_bw()
}
# Plot the turnaround time distributions
plot_metric("Turnaround Time", "[0-9]+_patrons")
# Plot the waiting time distributions
plot_metric("Waiting Time", "[0-9]+_patrons")
# Load the required libraries
library(ggplot2)
library(dplyr)
library(readr)
# Function to plot the distributions and averages
plot_metric <- function(metric_name, file_pattern) {
# Read the data files
fcfs_files <- list.files(pattern = paste0("^metric_times_0_with_", file_pattern, ".csv$"))
sjf_files <- list.files(pattern = paste0("^metric_times_1_with_", file_pattern, ".csv$"))
fcfs_data <- lapply(fcfs_files, read_csv) %>% dplyr::bind_rows()
sjf_data <- lapply(sjf_files, read_csv) %>% dplyr::bind_rows()
# Calculate averages
fcfs_avg <- mean(fcfs_data[[metric_name]], na.rm = TRUE)
sjf_avg <- mean(sjf_data[[metric_name]], na.rm = TRUE)
# Plot the distributions
ggplot() +
geom_histogram(data = fcfs_data, aes(x = .data[[metric_name]], fill = "FCFS"), alpha = 0.5, bins = 30) +
geom_histogram(data = sjf_data, aes(x = .data[[metric_name]], fill = "SJF"), alpha = 0.5, bins = 30) +
facet_wrap(~Patron.ID, ncol = 3) +
labs(
title = paste(metric_name, "Distributions"),
x = metric_name,
y = "Frequency",
fill = "Algorithm"
) +
geom_vline(xintercept = fcfs_avg, color = "red", linetype = "dashed", size = 1) +
geom_vline(xintercept = sjf_avg, color = "blue", linetype = "dashed", size = 1) +
annotate("text", x = Inf, y = Inf, label = paste("FCFS Average:", round(fcfs_avg, 2)), hjust = 1.1, vjust = 1.5, color = "red") +
annotate("text", x = Inf, y = Inf, label = paste("SJF Average:", round(sjf_avg, 2)), hjust = 1.1, vjust = 2, color = "blue") +
theme_bw()
}
# Plot the turnaround time distributions
plot_metric("Turnaround Time", "[0-9]+_patrons")
library(vctrs)
install.packages("dplyr")
library(dplyr)
library(readr)
# Function to plot the distributions and averages
plot_metric <- function(metric_name, file_pattern) {
# Read the data files
fcfs_files <- list.files(pattern = paste0("^metric_times_0_with_", file_pattern, ".csv$"))
sjf_files <- list.files(pattern = paste0("^metric_times_1_with_", file_pattern, ".csv$"))
fcfs_data <- lapply(fcfs_files, read_csv) %>% dplyr::bind_rows()
sjf_data <- lapply(sjf_files, read_csv) %>% dplyr::bind_rows()
# Calculate averages
fcfs_avg <- mean(fcfs_data[[metric_name]], na.rm = TRUE)
sjf_avg <- mean(sjf_data[[metric_name]], na.rm = TRUE)
# Plot the distributions
ggplot() +
geom_histogram(data = fcfs_data, aes(x = .data[[metric_name]], fill = "FCFS"), alpha = 0.5, bins = 30) +
geom_histogram(data = sjf_data, aes(x = .data[[metric_name]], fill = "SJF"), alpha = 0.5, bins = 30) +
facet_wrap(~Patron.ID, ncol = 3) +
labs(
title = paste(metric_name, "Distributions"),
x = metric_name,
y = "Frequency",
fill = "Algorithm"
) +
geom_vline(xintercept = fcfs_avg, color = "red", linetype = "dashed", size = 1) +
geom_vline(xintercept = sjf_avg, color = "blue", linetype = "dashed", size = 1) +
annotate("text", x = Inf, y = Inf, label = paste("FCFS Average:", round(fcfs_avg, 2)), hjust = 1.1, vjust = 1.5, color = "red") +
annotate("text", x = Inf, y = Inf, label = paste("SJF Average:", round(sjf_avg, 2)), hjust = 1.1, vjust = 2, color = "blue") +
theme_bw()
}
# Plot the turnaround time distributions
plot_metric("Turnaround Time", "[0-9]+_patrons")
# Plot the waiting time distributions
plot_metric("Waiting Time", "[0-9]+_patrons")
# Plot the response time distributions
plot_metric("Response Time", "[0-9]+_patrons")
# Load the required libraries
library(ggplot2)
# Function to plot the distributions and averages
plot_metric <- function(metric_name, file_pattern) {
# Read the data files
fcfs_files <- list.files(pattern = paste0("^metric_times_0_with_", file_pattern, ".csv$"))
sjf_files <- list.files(pattern = paste0("^metric_times_1_with_", file_pattern, ".csv$"))
fcfs_data <- do.call(rbind, lapply(fcfs_files, read.csv))
sjf_data <- do.call(rbind, lapply(sjf_files, read.csv))
# Calculate averages
fcfs_avg <- mean(fcfs_data[[metric_name]], na.rm = TRUE)
sjf_avg <- mean(sjf_data[[metric_name]], na.rm = TRUE)
# Plot the distributions
ggplot() +
geom_histogram(data = fcfs_data, aes(x = .data[[metric_name]], fill = "FCFS"), alpha = 0.5, bins = 30) +
geom_histogram(data = sjf_data, aes(x = .data[[metric_name]], fill = "SJF"), alpha = 0.5, bins = 30) +
facet_wrap(~Patron.ID, ncol = 3) +
labs(
title = paste(metric_name, "Distributions"),
x = metric_name,
y = "Frequency",
fill = "Algorithm"
) +
geom_vline(xintercept = fcfs_avg, color = "red", linetype = "dashed", size = 1) +
geom_vline(xintercept = sjf_avg, color = "blue", linetype = "dashed", size = 1) +
annotate("text", x = Inf, y = Inf, label = paste("FCFS Average:", round(fcfs_avg, 2)), hjust = 1.1, vjust = 1.5, color = "red") +
annotate("text", x = Inf, y = Inf, label = paste("SJF Average:", round(sjf_avg, 2)), hjust = 1.1, vjust = 2, color = "blue") +
theme_bw()
}
# Plot the turnaround time distributions
plot_metric("Turnaround Time", "[0-9]+_patrons")
